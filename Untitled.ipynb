{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b277e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:2.12.1-cpu'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "from sagemaker import image_uris\n",
    "image_uris.retrieve(framework='tensorflow',region='us-east-1',version='2.12.1',image_scope='inference',instance_type='ml.c5.4xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e63e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 520713654638.dkr.ecr.us-east-1.amazonaws.com    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88024bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0-cpu: Pulling from sagemaker-tensorflow-serving\n",
      "\n",
      "\u001b[1B8f4ce990: Pulling fs layer \n",
      "\u001b[1B282d9c4b: Pulling fs layer \n",
      "\u001b[1B3db6dc03: Pulling fs layer \n",
      "\u001b[1Bc605f3f1: Pulling fs layer \n",
      "\u001b[1B10487652: Pulling fs layer \n",
      "\u001b[1Bdde97789: Pulling fs layer \n",
      "\u001b[1Bb514193e: Pulling fs layer \n",
      "\u001b[1B9f2d3d2a: Pulling fs layer \n",
      "\u001b[1Be4419145: Pull complete 874kB/1.874kBBA\u001b[2K\u001b[5A\u001b[2K\u001b[9A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[9A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[3A\u001b[2K\u001b[4A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[4A\u001b[2K\u001b[9A\u001b[2K\u001b[4A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[9A\u001b[2K\u001b[7A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[5A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2KDigest: sha256:026c2a51a2e9e258481b17c110f9c9640dc010bf71463d4bd31e925ced7c6a49\n",
      "Status: Downloaded newer image for 520713654638.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tensorflow-serving:1.12.0-cpu\n",
      "520713654638.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tensorflow-serving:1.12.0-cpu\n"
     ]
    }
   ],
   "source": [
    "!docker pull 520713654638.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tensorflow-serving:1.12.0-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb7dc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.sparse\n",
    "from sagemaker import image_uris\n",
    "image_uris.retrieve(framework='tensorflow',region='us-east-1',version='2.12.0',image_scope='training',instance_type='ml.c5.4xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac684e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin  763104351884.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8fcb6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                                  TAG          IMAGE ID       CREATED       SIZE\n",
      "520713654638.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tensorflow-serving   1.12.0-cpu   27aee10a9f6a   5 years ago   377MB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f20e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Building 0.0s (0/1)                                          docker:default\n",
      "\u001b[?25h\u001b[1A\u001b[0G\u001b[?25l[+] Building 0.2s (2/2) FINISHED                                 docker:default\n",
      "\u001b[34m => [internal] load build definition from Dockerfile.train                 0.0s\n",
      "\u001b[0m\u001b[34m => => transferring dockerfile: 248B                                       0.0s\n",
      "\u001b[0m\u001b[31m => ERROR [internal] load metadata for 763104351884.dkr.ecr.us-east-1.ama  0.0s\n",
      "\u001b[0m\u001b[?25h------\n",
      " > [internal] load metadata for 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310:\n",
      "------\n",
      "Dockerfile.train:1\n",
      "--------------------\n",
      "   1 | >>> FROM 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310\n",
      "   2 |     \n",
      "   3 |     RUN pip install pandas scikit-learn numpy joblib\n",
      "--------------------\n",
      "ERROR: failed to solve: 763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310: unexpected status from HEAD request to https://763104351884.dkr.ecr.us-east-1.amazonaws.com/v2/tensorflow-training/manifests/2.12.0-cpu-py310: 401 Unauthorized\n"
     ]
    }
   ],
   "source": [
    "!docker build -t 715867985850.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310-pippo -f Dockerfile.train ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b509303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPOSITORY                                                                  TAG          IMAGE ID       CREATED       SIZE\n",
      "520713654638.dkr.ecr.us-east-1.amazonaws.com/sagemaker-tensorflow-serving   1.12.0-cpu   27aee10a9f6a   5 years ago   377MB\n"
     ]
    }
   ],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df43b1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: tensorflow-training-2024-11-22-10-16-47-377\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.local.image:'Docker Compose' is not installed. Proceeding to check for 'docker-compose' CLI.\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker Compose CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### ESTIMATOR FIT STARTED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:sagemaker:Please check the troubleshooting guide for common errors: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html#sagemaker-python-sdk-troubleshooting-create-training-job\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Invalid data source: /home/ec2-user/SageMaker/2023-25.ML.UFS14/data/input/house_price_regression_dataset.csv does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 19\u001b[0m\n\u001b[1;32m      9\u001b[0m estimator\u001b[38;5;241m=\u001b[39mEstimator(\n\u001b[1;32m     10\u001b[0m     image_uri\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m715867985850.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310-pippo\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     role\u001b[38;5;241m=\u001b[39mrole,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     output_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile://\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/data/output\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m##### ESTIMATOR FIT STARTED\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfile://\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/data/input/house_price_regression_dataset.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m##### ESTIMATOR FIT COMPLETED\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/estimator.py:1369\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_for_training(job_name\u001b[38;5;241m=\u001b[39mjob_name)\n\u001b[1;32m   1368\u001b[0m experiment_config \u001b[38;5;241m=\u001b[39m check_and_get_run_experiment_config(experiment_config)\n\u001b[0;32m-> 1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job \u001b[38;5;241m=\u001b[39m \u001b[43m_TrainingJob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_new\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1371\u001b[0m forward_to_mlflow_tracking_server \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/estimator.py:2498\u001b[0m, in \u001b[0;36m_TrainingJob.start_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   2495\u001b[0m train_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_train_args(estimator, inputs, experiment_config)\n\u001b[1;32m   2497\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain args after processing defaults: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, train_args)\n\u001b[0;32m-> 2498\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrain_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(estimator\u001b[38;5;241m.\u001b[39msagemaker_session, estimator\u001b[38;5;241m.\u001b[39m_current_job_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:1055\u001b[0m, in \u001b[0;36mSession.train\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, training_image_config, infra_check_config, container_entry_point, container_arguments, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy, remote_debug_config, session_chaining_config)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m   1051\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the troubleshooting guide for common errors: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, troubleshooting\n\u001b[1;32m   1052\u001b[0m         )\n\u001b[1;32m   1053\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m-> 1055\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_create_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:6606\u001b[0m, in \u001b[0;36mSession._intercept_create_request\u001b[0;34m(self, request, create, func_name)\u001b[0m\n\u001b[1;32m   6589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_intercept_create_request\u001b[39m(\n\u001b[1;32m   6590\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   6591\u001b[0m     request: typing\u001b[38;5;241m.\u001b[39mDict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6594\u001b[0m     \u001b[38;5;66;03m# pylint: disable=unused-argument\u001b[39;00m\n\u001b[1;32m   6595\u001b[0m ):\n\u001b[1;32m   6596\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function intercepts the create job request.\u001b[39;00m\n\u001b[1;32m   6597\u001b[0m \n\u001b[1;32m   6598\u001b[0m \u001b[38;5;124;03m    PipelineSession inherits this Session class and will override\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6604\u001b[0m \u001b[38;5;124;03m        func_name (str): the name of the function needed intercepting\u001b[39;00m\n\u001b[1;32m   6605\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:1053\u001b[0m, in \u001b[0;36mSession.train.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   1046\u001b[0m troubleshooting \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#sagemaker-python-sdk-troubleshooting-create-training-job\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m )\n\u001b[1;32m   1050\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the troubleshooting guide for common errors: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, troubleshooting\n\u001b[1;32m   1052\u001b[0m )\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py:1044\u001b[0m, in \u001b[0;36mSession.train.<locals>.submit\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating training-job with name: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, job_name)\n\u001b[1;32m   1043\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m.\u001b[39mdumps(request, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m-> 1044\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_training_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1046\u001b[0m     troubleshooting \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1047\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-python-sdk-troubleshooting.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#sagemaker-python-sdk-troubleshooting-create-training-job\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1049\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py:149\u001b[0m, in \u001b[0;36m_telemetry_emitter.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m caught_ex:\n\u001b[0;32m--> 149\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m caught_ex\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response  \u001b[38;5;66;03m# pylint: disable=W0150\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/telemetry/telemetry_logging.py:120\u001b[0m, in \u001b[0;36m_telemetry_emitter.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m start_timer \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# Call the original function\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     stop_timer \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m    122\u001b[0m     elapsed \u001b[38;5;241m=\u001b[39m stop_timer \u001b[38;5;241m-\u001b[39m start_timer\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/local_session.py:216\u001b[0m, in \u001b[0;36mLocalSagemakerClient.create_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, Environment, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHyperParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    215\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training job\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 216\u001b[0m \u001b[43mtraining_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mInputDataConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOutputDataConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEnvironment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTrainingJobName\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m LocalSagemakerClient\u001b[38;5;241m.\u001b[39m_training_jobs[TrainingJobName] \u001b[38;5;241m=\u001b[39m training_job\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/entities.py:252\u001b[0m, in \u001b[0;36m_LocalTrainingJob.start\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, environment, job_name)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_TRAINING\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment \u001b[38;5;241m=\u001b[39m environment\n\u001b[0;32m--> 252\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_artifacts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_data_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvironment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_COMPLETED\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/image.py:275\u001b[0m, in \u001b[0;36m_SageMakerContainer.train\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, environment, job_name)\u001b[0m\n\u001b[1;32m    272\u001b[0m os\u001b[38;5;241m.\u001b[39mmkdir(shared_dir)\n\u001b[1;32m    274\u001b[0m data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_tmp_folder()\n\u001b[0;32m--> 275\u001b[0m volumes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_training_volumes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_data_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m# If local, source directory needs to be updated to mounted /opt/ml/code path\u001b[39;00m\n\u001b[1;32m    279\u001b[0m hyperparameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_local_src_path(\n\u001b[1;32m    280\u001b[0m     hyperparameters, key\u001b[38;5;241m=\u001b[39msagemaker\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mDIR_PARAM_NAME\n\u001b[1;32m    281\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/image.py:568\u001b[0m, in \u001b[0;36m_SageMakerContainer._prepare_training_volumes\u001b[0;34m(self, data_dir, input_data_config, output_data_config, hyperparameters)\u001b[0m\n\u001b[1;32m    565\u001b[0m     channel_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, channel_name)\n\u001b[1;32m    566\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(channel_dir)\n\u001b[0;32m--> 568\u001b[0m     data_source \u001b[38;5;241m=\u001b[39m \u001b[43msagemaker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_source_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m     volumes\u001b[38;5;241m.\u001b[39mappend(_Volume(data_source\u001b[38;5;241m.\u001b[39mget_root_dir(), channel\u001b[38;5;241m=\u001b[39mchannel_name))\n\u001b[1;32m    571\u001b[0m \u001b[38;5;66;03m# If there is a training script directory and it is a local directory,\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;66;03m# mount it to the container.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/data.py:52\u001b[0m, in \u001b[0;36mget_data_source_instance\u001b[0;34m(data_source, sagemaker_session)\u001b[0m\n\u001b[1;32m     50\u001b[0m parsed_uri \u001b[38;5;241m=\u001b[39m urlparse(data_source)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed_uri\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileDataSource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_uri\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetloc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mparsed_uri\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parsed_uri\u001b[38;5;241m.\u001b[39mscheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m S3DataSource(parsed_uri\u001b[38;5;241m.\u001b[39mnetloc, parsed_uri\u001b[38;5;241m.\u001b[39mpath, sagemaker_session)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/local/data.py:126\u001b[0m, in \u001b[0;36mLocalFileDataSource.__init__\u001b[0;34m(self, root_path)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(root_path)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_path):\n\u001b[0;32m--> 126\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid data source: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_path)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Invalid data source: /home/ec2-user/SageMaker/2023-25.ML.UFS14/data/input/house_price_regression_dataset.csv does not exist."
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import os\n",
    "\n",
    "role=get_execution_role()\n",
    "\n",
    "hyperparameters={'epochs': 1}\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri='715867985850.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310-pippo',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='local',\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path='file://{}/data/output'.format(os.getcwd())\n",
    ")\n",
    "\n",
    "print('##### ESTIMATOR FIT STARTED')\n",
    "estimator.fit('file://{}/data/input/house_price_regression_dataset.csv'.format(os.getcwd()))\n",
    "print('##### ESTIMATOR FIT COMPLETED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "187b6ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar (child): data/output/output.tar.gz: Cannot open: No such file or directory\n",
      "tar (child): Error is not recoverable: exiting now\n",
      "tar: Child returned status 2\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    }
   ],
   "source": [
    "!tar -xzf data/output/output.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c35fafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar (child): ./data/output/model.tar.gz: Cannot open: No such file or directory\n",
      "tar (child): Error is not recoverable: exiting now\n",
      "tar: Child returned status 2\n",
      "tar: Error is not recoverable: exiting now\n"
     ]
    }
   ],
   "source": [
    "!tar -xzf ./data/output/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc75b5f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/SageMaker/2023-25.ML.UFS14/main.py\", line 4, in <module>\n",
      "    input_dir = os.environ['SM_INPUT_DIR']\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/os.py\", line 680, in __getitem__\n",
      "    raise KeyError(key) from None\n",
      "KeyError: 'SM_INPUT_DIR'\n"
     ]
    }
   ],
   "source": [
    "!SM_MODEL_DIR=\"./data/output\" python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ee10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec804e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# Specify an image name\n",
    "image_name=tensorflow-training\n",
    "echo \"image_name: ${image_name} ######################\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo \"account: ${account} ######################\"\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "echo \"region: ${region} ######################\"\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:2.12.0-cpu-py310-pippo\"\n",
    "echo \"fullname: ${fullname} ######################\"\n",
    "aws ecr create-repository --repository-name \"${image_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a666ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin  715867985850.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff78ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b3fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag tensorflow-training:2.12.0-cpu-py310-pippo 715867985850.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310-pippo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ca489",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7989f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push 715867985850.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310-pippo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69424be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "import os\n",
    "\n",
    "role=get_execution_role()\n",
    "\n",
    "hyperparameters={'epochs': 1}\n",
    "\n",
    "estimator=Estimator(\n",
    "    image_uri='715867985850.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.12.0-cpu-py310-pippo',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.p2.xlarge',\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path='s3://itfilippoconsole/data/output'\n",
    ")\n",
    "\n",
    "print('##### ESTIMATOR FIT STARTED')\n",
    "estimator.fit('s3://itfilippoconsole/data/input/house_price_regression_dataset.csv')\n",
    "print('##### ESTIMATOR FIT COMPLETED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b92ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xzf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b65479",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157fbe68",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dab921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.saving import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2574f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "model = models.load_model(\"abalone_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c9c7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predict_input=np.array([[0.475,0.37,0.125,0.5095,0.2165,0.1125,0.165,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6636a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = model.predict(predict_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831980d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dumps({\"predict_result\": predict_result.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908cff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "# Specify an image name\n",
    "image_name=tensorflow-inference\n",
    "echo \"image_name: ${image_name} ######################\"\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "echo \"account: ${account} ######################\"\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "echo \"region: ${region} ######################\"\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image_name}:2.12.0-cpu-py310-pluto-2\"\n",
    "echo \"fullname: ${fullname} ######################\"\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${image_name}\"\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "aws ecr create-repository --repository-name \"${image_name}\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bef9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker build -t 715867985850.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:mondo -f Dockerfile.inference ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b91391",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbee8afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker push 715867985850.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:mondo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c06907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin 715867985850.dkr.ecr.us-east-1.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "import boto3\n",
    "import datetime\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deployment.html\n",
    "\n",
    "#Set up autenticazione\n",
    "my_session = boto3.session.Session()\n",
    "aws_region = my_session.region_name\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=aws_region)\n",
    "sagemaker_role = get_execution_role()\n",
    "\n",
    "model_name = 'Il-top'\n",
    "\n",
    "# Create model\n",
    "create_model_response = sagemaker_client.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = sagemaker_role,\n",
    "    PrimaryContainer = {\n",
    "        'Image': '715867985850.dkr.ecr.us-east-1.amazonaws.com/tensorflow-inference:mondo',\n",
    "        'ModelDataUrl': 's3://trainjob/data/output/training_job-2024-11-05-14-05-20/output/model(3).tar.gz',\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343f7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an endpoint config name. Here we create one based on the date  \n",
    "# so it we can search endpoints based on creation time.\n",
    "endpoint_config_name = 'la-mia-prima-api-inferenza-config'\n",
    "\n",
    "instance_type = 'ml.p2.xlarge'\n",
    "\n",
    "endpoint_config_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    # You will specify this name in a CreateEndpoint request.\n",
    "    # List of ProductionVariant objects, one for each model that you want to host at this endpoint.\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": \"variant1\", # The name of the production variant.\n",
    "            \"ModelName\": model_name,\n",
    "            \"InstanceType\": instance_type, # Specify the compute instance type.\n",
    "            \"InitialInstanceCount\": 1 # Number of instances to launch initially.\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"Created EndpointConfig: {endpoint_config_response['EndpointConfigArn']}\")\n",
    "\n",
    "# The name of the endpoint. The name must be unique within an AWS Region in your AWS account.\n",
    "endpoint_name = 'la-mia-prima-api-inferenza'\n",
    "\n",
    "create_endpoint_response = sagemaker_client.create_endpoint(\n",
    "                                            EndpointName=endpoint_name, \n",
    "                                            EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d6783d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974bab20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
